{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f0bb94",
   "metadata": {},
   "source": [
    "# SMS 相似性配對 - LLM 輔助對比學習正樣本生成\n",
    "\n",
    "此 notebook 使用 LLM (Together AI) 來找出簡訊數據中兩兩相似的內容，為對比學習生成正樣本對。\n",
    "\n",
    "## 流程概述\n",
    "1. 載入 SMS 數據\n",
    "2. 使用 LLM 比較簡訊相似性\n",
    "3. 生成相似簡訊對的 CSV 檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb01baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from together import Together\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from typing import List, Tuple\n",
    "from itertools import combinations\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb61081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功初始化 4 個 Together AI 客戶端\n",
      "API Key 1: 1f3b522748...\n",
      "API Key 2: 542d70c17d...\n",
      "API Key 3: 713f17cd14...\n",
      "API Key 4: db7765986a...\n"
     ]
    }
   ],
   "source": [
    "# 設置 Together AI API 客戶端\n",
    "# 讀取 API keys\n",
    "try:\n",
    "    with open(\"data_game/together_api_key.txt\", \"r\") as f:\n",
    "        api_keys = [line.strip() for line in f.readlines() if line.strip()]\n",
    "except FileNotFoundError:\n",
    "    print(\"請確保 data_game/together_api_key.txt 文件存在\")\n",
    "    raise\n",
    "\n",
    "# 確保有足夠的 API key\n",
    "if len(api_keys) < 4:\n",
    "    raise ValueError(\"請在 together_api_key.txt 文件中提供四個 API key，每行一個\")\n",
    "\n",
    "# 創建四個 Together 客戶端進行負載均衡\n",
    "together_clients = [Together(api_key=key) for key in api_keys]\n",
    "\n",
    "# 追蹤當前使用哪個客戶端\n",
    "_current_client_index = 0\n",
    "\n",
    "def get_current_together_client():\n",
    "    \"\"\"循環返回四個 Together 客戶端\"\"\"\n",
    "    global _current_client_index\n",
    "    current_client = together_clients[_current_client_index]\n",
    "    _current_client_index = (_current_client_index + 1) % len(together_clients)\n",
    "    return current_client\n",
    "\n",
    "print(f\"已成功初始化 {len(together_clients)} 個 Together AI 客戶端\")\n",
    "for i, key in enumerate(api_keys):\n",
    "    print(f\"API Key {i+1}: {key[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c9688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入了 209481 筆簡訊數據\n",
      "\n",
      "數據結構:\n",
      "   sms_id                                           sms_body  label  name_flg\n",
      "0  162569  親愛的家長您好，寶寶即將滿一歲，記得安排回兒科施打麻疹腮腺炎德國麻疹(MMR)疫苗，並攜帶健...    NaN       NaN\n",
      "1  314614  富邦帳戶轉帳完成：您於05/28上午10:14轉出NT$4,200元至王道銀行帳戶末四碼71...    NaN       NaN\n",
      "2  355174  【測驗通知】張睿庭學員：本週五為「自然科探究與實作能力評量」，共90分鐘，請攜帶實驗筆記與護...    NaN       NaN\n",
      "3   28258  詹睿哲君，您好：提醒您5月分手機分期款NT$2,100至今尚未入帳，系統已發送3次通知未回覆...    NaN       NaN\n",
      "4  376466  尊敬的客戶，這是來自中信銀行的提醒。您的貸款款項已過期，請您儘速償還。若已繳款，請無需理會此...    NaN       NaN\n",
      "\n",
      "欄位: ['sms_id', 'sms_body', 'label', 'name_flg']\n",
      "\n",
      "過濾後剩餘 209481 筆有效簡訊\n",
      "\n",
      "=== Label 分布分析 ===\n",
      "label\n",
      "1.0    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "旅遊類型簡訊 (label=1): 1000 筆\n",
      "非旅遊類型簡訊 (label≠1): 208481 筆\n",
      "\n",
      "=== 旅遊類型簡訊樣本 ===\n",
      "ID 254284: 來場異國文化之旅！「異域風情」旅行社推出的七日印度之旅，帶您探索德里、阿格拉等地，感受印度的歷史與文化底蘊。報名即享早鳥優惠，立刻報名，開啟這場精彩的印度之旅！報名熱線：02-23335588。\n",
      "ID 229496: 李麗芬小姐，您的「日本沖繩海島之旅」已確認，所有行程與住宿將於出發前三天發送至您的電子信箱。\n",
      "ID 44913: 👨‍👩‍👧王子維與林郁茹報名參加「北海道雪地溫泉假期」，李宥帆也強烈推薦滑雪課程＋夜間泡湯體驗，限時早鳥現折$2000！\n",
      "\n",
      "=== 非旅遊類型簡訊樣本 ===\n",
      "ID 162569: 親愛的家長您好，寶寶即將滿一歲，記得安排回兒科施打麻疹腮腺炎德國麻疹(MMR)疫苗，並攜帶健保卡與兒童健康手冊。\n",
      "ID 314614: 富邦帳戶轉帳完成：您於05/28上午10:14轉出NT$4,200元至王道銀行帳戶末四碼7183，交易編號已同步入帳。\n",
      "ID 355174: 【測驗通知】張睿庭學員：本週五為「自然科探究與實作能力評量」，共90分鐘，請攜帶實驗筆記與護目鏡至理化教室參加。\n"
     ]
    }
   ],
   "source": [
    "# 載入 SMS 數據並分析 label 分布\n",
    "df = pd.read_csv(\"datagame_sms_stage1.csv\")\n",
    "print(f\"載入了 {len(df)} 筆簡訊數據\")\n",
    "print(\"\\n數據結構:\")\n",
    "print(df.head())\n",
    "print(f\"\\n欄位: {list(df.columns)}\")\n",
    "\n",
    "# 只保留有簡訊內容的數據\n",
    "df = df.dropna(subset=['sms_body'])\n",
    "print(f\"\\n過濾後剩餘 {len(df)} 筆有效簡訊\")\n",
    "\n",
    "# 分析 label 分布\n",
    "print(f\"\\n=== Label 分布分析 ===\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# 分離旅遊類型和非旅遊類型簡訊\n",
    "travel_sms = df[df['label'] == 1].copy()\n",
    "non_travel_sms = df[df['label'] != 1].copy()\n",
    "\n",
    "print(f\"\\n旅遊類型簡訊 (label=1): {len(travel_sms)} 筆\")\n",
    "print(f\"非旅遊類型簡訊 (label≠1): {len(non_travel_sms)} 筆\")\n",
    "\n",
    "# 顯示一些樣本\n",
    "print(f\"\\n=== 旅遊類型簡訊樣本 ===\")\n",
    "for i, row in travel_sms.head(3).iterrows():\n",
    "    print(f\"ID {row['sms_id']}: {row['sms_body']}\")\n",
    "\n",
    "print(f\"\\n=== 非旅遊類型簡訊樣本 ===\")\n",
    "for i, row in non_travel_sms.head(3).iterrows():\n",
    "    print(f\"ID {row['sms_id']}: {row['sms_body']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c71f34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批量相似性判斷功能已設置完成\n"
     ]
    }
   ],
   "source": [
    "# 限流設置\n",
    "RPM = 60                # requests/min\n",
    "WINDOW = 60             # sec\n",
    "MAX_RETRY = 3           # retries\n",
    "MODEL_ID = \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"\n",
    "\n",
    "# 請求紀錄\n",
    "_req_log = []\n",
    "\n",
    "def _throttle():\n",
    "    \"\"\"簡單的限流機制\"\"\"\n",
    "    now = time.time()\n",
    "    # 清理超過時間窗口的記錄\n",
    "    _req_log[:] = [t for t in _req_log if now - t < WINDOW]\n",
    "    \n",
    "    # 檢查是否需要等待\n",
    "    if len(_req_log) >= RPM:\n",
    "        wait_time = WINDOW - (now - _req_log[0])\n",
    "        if wait_time > 0:\n",
    "            time.sleep(wait_time)\n",
    "    \n",
    "    _req_log.append(now)\n",
    "\n",
    "# 設計批量相似性判斷的 prompt\n",
    "batch_similarity_prompt_template = textwrap.dedent(\n",
    "    \"\"\"\n",
    "    你是一個專業的文本相似性判斷助手。請仔細比較以下3個簡訊的內容，找出其中相似的簡訊對。\n",
    "    判斷標準:\n",
    "    1. 主題相似性：兩個簡訊是否討論相同或相關的主題\n",
    "    2. 意圖相似性：兩個簡訊的目的是否相似（如：通知、推廣、提醒等）\n",
    "    3. 內容相似性：具體內容是否有重疊或相關性\n",
    "    注意：\n",
    "    - 即使措詞不同，但如果主題和意圖相似，也應判斷為相似\n",
    "    - 只是格式相似但內容完全不同的簡訊不應判斷為相似\n",
    "    - 考慮簡訊的實際含義而非表面文字\n",
    "    請按照以下格式回答，每行一個比較結果：\n",
    "    A-B: 1 (如果簡訊A和B相似) 或 0 (如果不相似)\n",
    "    A-C: 1 (如果簡訊A和C相似) 或 0 (如果不相似)  \n",
    "    B-C: 1 (如果簡訊B和C相似) 或 0 (如果不相似)\n",
    "    簡訊A: {sms_a}\n",
    "    簡訊B: {sms_b}\n",
    "    簡訊C: {sms_c}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def check_batch_sms_similarity(sms_list: List[Tuple[int, str]]) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    使用 LLM 批量判斷3個簡訊的相似性\n",
    "    \n",
    "    Args:\n",
    "        sms_list: [(sms_id, sms_body), ...] 最多3個簡訊\n",
    "    \n",
    "    Returns:\n",
    "        相似簡訊對的列表 [(id1, id2), ...]\n",
    "    \"\"\"\n",
    "    if len(sms_list) != 3:\n",
    "        raise ValueError(\"批量比較需要恰好3個簡訊\")\n",
    "    \n",
    "    (id_a, sms_a), (id_b, sms_b), (id_c, sms_c) = sms_list\n",
    "    \n",
    "    prompt = batch_similarity_prompt_template.format(\n",
    "        sms_a=sms_a, \n",
    "        sms_b=sms_b, \n",
    "        sms_c=sms_c\n",
    "    )\n",
    "    \n",
    "    client = get_current_together_client()\n",
    "    \n",
    "    for attempt in range(MAX_RETRY):\n",
    "        try:\n",
    "            _throttle()\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL_ID,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=20,  # 增加token數量以應對多行輸出\n",
    "                temperature=0.0,\n",
    "                stream=False,\n",
    "            )\n",
    "            \n",
    "            result = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # 解析結果\n",
    "            similar_pairs = []\n",
    "            lines = result.split('\\n')\n",
    "            \n",
    "            # 解析格式：A-B: 1, A-C: 0, B-C: 1\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if ':' in line:\n",
    "                    pair_part, similarity_part = line.split(':', 1)\n",
    "                    pair_part = pair_part.strip()\n",
    "                    similarity = similarity_part.strip()\n",
    "                    \n",
    "                    if similarity == '1':\n",
    "                        if pair_part.upper() == 'A-B':\n",
    "                            similar_pairs.append((id_a, id_b))\n",
    "                        elif pair_part.upper() == 'A-C':\n",
    "                            similar_pairs.append((id_a, id_c))\n",
    "                        elif pair_part.upper() == 'B-C':\n",
    "                            similar_pairs.append((id_b, id_c))\n",
    "            \n",
    "            return similar_pairs\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt + 1 >= MAX_RETRY:\n",
    "                print(f\"Error after {MAX_RETRY} attempts: {e}\")\n",
    "                print(f\"Raw response: {result if 'result' in locals() else 'No response'}\")\n",
    "                return []  # 失敗時返回空列表\n",
    "            \n",
    "            print(f\"Attempt {attempt + 1} failed: {e}. Retrying in 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "    \n",
    "    return []\n",
    "\n",
    "# 保留原始單對比較函數作為備用\n",
    "def check_sms_similarity(sms1: str, sms2: str) -> str:\n",
    "    \"\"\"使用 LLM 判斷兩個簡訊是否相似（單對比較）\"\"\"\n",
    "    similarity_prompt_template = textwrap.dedent(\n",
    "        \"\"\"\n",
    "        你是一個專業的文本相似性判斷助手。請仔細比較以下兩個簡訊的內容，判斷它們是否在語義上相似。\n",
    "\n",
    "        判斷標準:\n",
    "        1. 主題相似性：兩個簡訊是否討論相同或相關的主題\n",
    "        2. 意圖相似性：兩個簡訊的目的是否相似（如：通知、推廣、提醒等）\n",
    "        3. 內容相似性：具體內容是否有重疊或相關性\n",
    "        \n",
    "        注意：\n",
    "        - 即使措詞不同，但如果主題和意圖相似，也應判斷為相似\n",
    "        - 只是格式相似但內容完全不同的簡訊不應判斷為相似\n",
    "        - 考慮簡訊的實際含義而非表面文字\n",
    "\n",
    "        請只回答 \"1\"（相似）或 \"0\"（不相似），不要輸出其他內容。\n",
    "\n",
    "        簡訊1: {sms1}\n",
    "        \n",
    "        簡訊2: {sms2}\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    prompt = similarity_prompt_template.format(sms1=sms1, sms2=sms2)\n",
    "    \n",
    "    client = get_current_together_client()\n",
    "    \n",
    "    for attempt in range(MAX_RETRY):\n",
    "        try:\n",
    "            _throttle()\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL_ID,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=4,\n",
    "                temperature=0.0,\n",
    "                stream=False,\n",
    "            )\n",
    "            \n",
    "            result = response.choices[0].message.content.strip()\n",
    "            if result in [\"0\", \"1\"]:\n",
    "                return result\n",
    "            else:\n",
    "                print(f\"Warning: Unexpected output '{result}', treating as not similar\")\n",
    "                return \"0\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt + 1 >= MAX_RETRY:\n",
    "                print(f\"Error after {MAX_RETRY} attempts: {e}\")\n",
    "                return \"0\"  # 失敗時預設為不相似\n",
    "            \n",
    "            print(f\"Attempt {attempt + 1} failed: {e}. Retrying in 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "    \n",
    "    return \"0\"\n",
    "\n",
    "print(\"批量相似性判斷功能已設置完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3366560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批量同類型配對功能已設置完成\n"
     ]
    }
   ],
   "source": [
    "# 批量同類型簡訊配對函數\n",
    "def find_same_type_pairs_batch(df_subset: pd.DataFrame, max_pairs: int = None, description: str = \"\") -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    在同類型簡訊中使用批量比較找出相似對\n",
    "    \n",
    "    Args:\n",
    "        df_subset: 同類型的簡訊 DataFrame\n",
    "        max_pairs: 最大要找的相似對數量\n",
    "        description: 描述文字\n",
    "    \n",
    "    Returns:\n",
    "        相似簡訊對的列表 [(id1, id2), ...]\n",
    "    \"\"\"\n",
    "    if len(df_subset) < 3:\n",
    "        print(f\"{description}: 數據量不足（需要至少3筆），改用單對比較\")\n",
    "        return find_same_type_pairs_single(df_subset, max_pairs, description)\n",
    "    \n",
    "    similar_pairs = []\n",
    "    df_list = list(df_subset.iterrows())\n",
    "    \n",
    "    if max_pairs is None:\n",
    "        max_pairs = min(len(df_subset) * (len(df_subset) - 1) // 2, 1000)  # 預設最多1000對\n",
    "    \n",
    "    print(f\"\\n=== {description} (批量模式) ===\")\n",
    "    print(f\"將批量比較 {len(df_subset)} 筆簡訊\")\n",
    "    print(f\"目標找到 {max_pairs} 個相似對\")\n",
    "    \n",
    "    # 計算需要的批次數量（每3個簡訊為一批）\n",
    "    total_batches = len(df_list) // 3\n",
    "    if len(df_list) % 3 != 0:\n",
    "        total_batches += 1\n",
    "    \n",
    "    # 使用 tqdm 顯示進度\n",
    "    with tqdm(total=min(total_batches, max_pairs), desc=f\"{description}批量比較進度\") as pbar:\n",
    "        batch_count = 0\n",
    "        \n",
    "        # 批量處理：每3個簡訊為一組\n",
    "        for i in range(0, len(df_list), 3):\n",
    "            if len(similar_pairs) >= max_pairs:\n",
    "                break\n",
    "            \n",
    "            # 取3個簡訊進行批量比較\n",
    "            batch = df_list[i:i+3]\n",
    "            if len(batch) == 3:\n",
    "                # 準備批量比較的數據\n",
    "                sms_batch = [(row['sms_id'], row['sms_body']) for idx, row in batch]\n",
    "                \n",
    "                # 進行批量相似性判斷\n",
    "                batch_pairs = check_batch_sms_similarity(sms_batch)\n",
    "                \n",
    "                # 添加找到的相似對\n",
    "                for pair in batch_pairs:\n",
    "                    if len(similar_pairs) < max_pairs:\n",
    "                        similar_pairs.append(pair)\n",
    "                        \n",
    "                        # 找到並顯示簡訊內容\n",
    "                        id1, id2 = pair\n",
    "                        sms1 = df_subset[df_subset['sms_id'] == id1]['sms_body'].iloc[0]\n",
    "                        sms2 = df_subset[df_subset['sms_id'] == id2]['sms_body'].iloc[0]\n",
    "\n",
    "                \n",
    "                batch_count += 1\n",
    "                pbar.update(1)\n",
    "            \n",
    "            # 處理剩餘的1-2個簡訊（如果有的話）\n",
    "            elif len(batch) == 2 and len(similar_pairs) < max_pairs:\n",
    "                # 對剩餘的2個簡訊進行單對比較\n",
    "                row1, row2 = batch[0][1], batch[1][1]\n",
    "                is_similar = check_sms_similarity(row1['sms_body'], row2['sms_body'])\n",
    "                \n",
    "                if is_similar == \"1\":\n",
    "                    similar_pairs.append((row1['sms_id'], row2['sms_id']))\n",
    "                \n",
    "        \n",
    "        # 如果還需要更多相似對，繼續進行交叉批量比較\n",
    "        if len(similar_pairs) < max_pairs and len(df_list) >= 6:\n",
    "            print(f\"\\n進行交叉批量比較以找到更多相似對...\")\n",
    "            cross_batch_count = 0\n",
    "            max_cross_batches = min(50, max_pairs - len(similar_pairs))  # 限制交叉比較次數\n",
    "            \n",
    "            for i in range(0, len(df_list)-3, 6):  # 每6個簡訊取兩組進行交叉比較\n",
    "                if len(similar_pairs) >= max_pairs or cross_batch_count >= max_cross_batches:\n",
    "                    break\n",
    "                \n",
    "                # 取第一組3個簡訊\n",
    "                batch1 = df_list[i:i+3]\n",
    "                # 取第二組3個簡訊\n",
    "                batch2 = df_list[i+3:i+6] if i+6 <= len(df_list) else df_list[i+3:]\n",
    "                \n",
    "                if len(batch1) == 3 and len(batch2) >= 2:\n",
    "                    # 創建混合批次進行比較\n",
    "                    for j in range(len(batch2)):\n",
    "                        if len(similar_pairs) >= max_pairs:\n",
    "                            break\n",
    "                        \n",
    "                        # 取batch1的前2個 + batch2的第j個組成新的批次\n",
    "                        mixed_batch = [batch1[0], batch1[1], batch2[j]]\n",
    "                        sms_batch = [(row['sms_id'], row['sms_body']) for idx, row in mixed_batch]\n",
    "                        \n",
    "                        batch_pairs = check_batch_sms_similarity(sms_batch)\n",
    "                        \n",
    "                        for pair in batch_pairs:\n",
    "                            if len(similar_pairs) < max_pairs:\n",
    "                                # 檢查是否為新的相似對\n",
    "                                if pair not in similar_pairs and (pair[1], pair[0]) not in similar_pairs:\n",
    "                                    similar_pairs.append(pair)\n",
    "                                    \n",
    "                                    id1, id2 = pair\n",
    "                                    sms1 = df_subset[df_subset['sms_id'] == id1]['sms_body'].iloc[0]\n",
    "                                    sms2 = df_subset[df_subset['sms_id'] == id2]['sms_body'].iloc[0]\n",
    "                                    \n",
    "                cross_batch_count += 1\n",
    "                pbar.update(1)\n",
    "    \n",
    "    print(f\"\\n{description}完成！總共找到 {len(similar_pairs)} 個相似對\")\n",
    "    return similar_pairs\n",
    "\n",
    "# 單對比較函數（備用）\n",
    "def find_same_type_pairs_single(df_subset: pd.DataFrame, max_pairs: int = None, description: str = \"\") -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    在同類型簡訊中使用單對比較找出相似對（備用方法）\n",
    "    \"\"\"\n",
    "    if len(df_subset) < 2:\n",
    "        print(f\"{description}: 數據量不足，無法配對\")\n",
    "        return []\n",
    "    \n",
    "    similar_pairs = []\n",
    "    total_combinations = len(df_subset) * (len(df_subset) - 1) // 2\n",
    "    \n",
    "    if max_pairs is None:\n",
    "        max_pairs = min(total_combinations, 1000)\n",
    "    \n",
    "    print(f\"\\n=== {description} (單對模式) ===\")\n",
    "    print(f\"將比較 {len(df_subset)} 筆簡訊，總共 {total_combinations} 個組合\")\n",
    "    print(f\"目標找到 {max_pairs} 個相似對\")\n",
    "    \n",
    "    with tqdm(total=min(total_combinations, max_pairs * 5), desc=f\"{description}比較進度\") as pbar:\n",
    "        compared = 0\n",
    "        \n",
    "        for i, row1 in df_subset.iterrows():\n",
    "            if len(similar_pairs) >= max_pairs:\n",
    "                break\n",
    "                \n",
    "            for j, row2 in df_subset.iterrows():\n",
    "                if i >= j:\n",
    "                    continue\n",
    "                \n",
    "                compared += 1\n",
    "                pbar.update(1)\n",
    "                \n",
    "                if len(similar_pairs) >= max_pairs:\n",
    "                    break\n",
    "                \n",
    "                if compared > max_pairs * 5:\n",
    "                    break\n",
    "                \n",
    "                is_similar = check_sms_similarity(row1['sms_body'], row2['sms_body'])\n",
    "                \n",
    "                if is_similar == \"1\":\n",
    "                    similar_pairs.append((row1['sms_id'], row2['sms_id']))\n",
    "                    print(f\"\\n找到第 {len(similar_pairs)} 個{description}相似對:\")\n",
    "                    print(f\"ID {row1['sms_id']}: {row1['sms_body'][:50]}...\")\n",
    "                    print(f\"ID {row2['sms_id']}: {row2['sms_body'][:50]}...\")\n",
    "                    \n",
    "            if len(similar_pairs) >= max_pairs or compared > max_pairs * 5:\n",
    "                break\n",
    "    \n",
    "    print(f\"\\n{description}完成！總共找到 {len(similar_pairs)} 個相似對\")\n",
    "    return similar_pairs\n",
    "\n",
    "# 設置預設使用批量比較\n",
    "find_same_type_pairs = find_same_type_pairs_batch\n",
    "\n",
    "print(\"批量同類型配對功能已設置完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e14a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始執行分類配對策略...\n",
      "\n",
      "🏖️ 第一階段：旅遊類型簡訊配對\n",
      "\n",
      "=== 旅遊類型簡訊 (批量模式) ===\n",
      "將批量比較 1000 筆簡訊\n",
      "目標找到 400 個相似對\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "旅遊類型簡訊批量比較進度:   0%|          | 0/334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "旅遊類型簡訊批量比較進度:  60%|██████    | 201/334 [50:11<33:12, 14.98s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "旅遊類型簡訊完成！總共找到 400 個相似對\n",
      "\n",
      "🏢 第二階段：非旅遊類型簡訊配對\n",
      "從 208481 筆非旅遊簡訊中採樣 40000 筆\n",
      "\n",
      "=== 非旅遊類型簡訊 (批量模式) ===\n",
      "將批量比較 40000 筆簡訊\n",
      "目標找到 4000 個相似對\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "非旅遊類型簡訊批量比較進度:  19%|█▉        | 755/4000 [3:23:25<26:50:13, 29.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Error code: 429 - {\"message\": \"You have reached the rate limit specific to this model meta-llama/Llama-3.3-70B-Instruct-Turbo-Free. The maximum rate limit for this model is 6.0 queries and 60000 tokens per minute. This limit differs from the general rate limits published at Together AI rate limits documentation (https://docs.together.ai/docs/rate-limits). For inquiries about increasing your model-specific rate limit, please contact our sales team (https://www.together.ai/forms/contact-sales)\", \"type_\": \"model_rate_limit\"}. Retrying in 60 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "非旅遊類型簡訊批量比較進度:  66%|██████▌   | 2635/4000 [8:53:59<10:41:00, 28.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Error code: 429 - {\"message\": \"You have reached the rate limit specific to this model meta-llama/Llama-3.3-70B-Instruct-Turbo-Free. The maximum rate limit for this model is 6.0 queries and 60000 tokens per minute. This limit differs from the general rate limits published at Together AI rate limits documentation (https://docs.together.ai/docs/rate-limits). For inquiries about increasing your model-specific rate limit, please contact our sales team (https://www.together.ai/forms/contact-sales)\", \"type_\": \"model_rate_limit\"}. Retrying in 60 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "非旅遊類型簡訊批量比較進度: 4734it [17:07:45, 120.68s/it]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Error code: 429 - {\"message\": \"You have reached the rate limit specific to this model meta-llama/Llama-3.3-70B-Instruct-Turbo-Free. The maximum rate limit for this model is 6.0 queries and 60000 tokens per minute. This limit differs from the general rate limits published at Together AI rate limits documentation (https://docs.together.ai/docs/rate-limits). For inquiries about increasing your model-specific rate limit, please contact our sales team (https://www.together.ai/forms/contact-sales)\", \"type_\": \"model_rate_limit\"}. Retrying in 60 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "非旅遊類型簡訊批量比較進度: 4737it [17:10:34, 72.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Error code: 429 - {\"message\": \"You have reached the rate limit specific to this model meta-llama/Llama-3.3-70B-Instruct-Turbo-Free. The maximum rate limit for this model is 6.0 queries and 60000 tokens per minute. This limit differs from the general rate limits published at Together AI rate limits documentation (https://docs.together.ai/docs/rate-limits). For inquiries about increasing your model-specific rate limit, please contact our sales team (https://www.together.ai/forms/contact-sales)\", \"type_\": \"model_rate_limit\"}. Retrying in 60 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "非旅遊類型簡訊批量比較進度: 4839it [17:51:33, 46.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Error code: 429 - {\"message\": \"You have reached the rate limit specific to this model meta-llama/Llama-3.3-70B-Instruct-Turbo-Free. The maximum rate limit for this model is 6.0 queries and 60000 tokens per minute. This limit differs from the general rate limits published at Together AI rate limits documentation (https://docs.together.ai/docs/rate-limits). For inquiries about increasing your model-specific rate limit, please contact our sales team (https://www.together.ai/forms/contact-sales)\", \"type_\": \"model_rate_limit\"}. Retrying in 60 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "非旅遊類型簡訊批量比較進度: 5107it [20:01:55, 119.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Error code: 503 - The server is overloaded or not ready yet.. Retrying in 60 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "非旅遊類型簡訊批量比較進度: 5808it [25:27:24, 34.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Error code: 429 - {\"message\": \"You have reached the rate limit specific to this model meta-llama/Llama-3.3-70B-Instruct-Turbo-Free. The maximum rate limit for this model is 6.0 queries and 60000 tokens per minute. This limit differs from the general rate limits published at Together AI rate limits documentation (https://docs.together.ai/docs/rate-limits). For inquiries about increasing your model-specific rate limit, please contact our sales team (https://www.together.ai/forms/contact-sales)\", \"type_\": \"model_rate_limit\"}. Retrying in 60 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "非旅遊類型簡訊批量比較進度: 5813it [25:32:46, 57.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Error code: 503 - The server is overloaded or not ready yet.. Retrying in 60 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "非旅遊類型簡訊批量比較進度: 7113it [32:57:29, 10.09s/it] "
     ]
    }
   ],
   "source": [
    "# 執行分類配對策略\n",
    "print(\"開始執行分類配對策略...\")\n",
    "\n",
    "# ========== 第一階段：旅遊類型簡訊配對 ==========\n",
    "print(f\"\\n🏖️ 第一階段：旅遊類型簡訊配對\")\n",
    "travel_pairs = find_same_type_pairs(\n",
    "    df_subset=travel_sms,\n",
    "    max_pairs=400,  # 盡量找出所有旅遊類型的相似對\n",
    "    description=\"旅遊類型簡訊\"\n",
    ")\n",
    "\n",
    "# ========== 第二階段：非旅遊類型簡訊配對 ==========\n",
    "print(f\"\\n🏢 第二階段：非旅遊類型簡訊配對\")\n",
    "\n",
    "# 從非旅遊類型中採樣800筆\n",
    "NON_TRAVEL_SAMPLE_SIZE = 40000\n",
    "if len(non_travel_sms) > NON_TRAVEL_SAMPLE_SIZE:\n",
    "    non_travel_sample = non_travel_sms.sample(n=NON_TRAVEL_SAMPLE_SIZE, random_state=42)\n",
    "    print(f\"從 {len(non_travel_sms)} 筆非旅遊簡訊中採樣 {NON_TRAVEL_SAMPLE_SIZE} 筆\")\n",
    "else:\n",
    "    non_travel_sample = non_travel_sms\n",
    "    print(f\"使用全部 {len(non_travel_sms)} 筆非旅遊簡訊\")\n",
    "\n",
    "non_travel_pairs = find_same_type_pairs(\n",
    "    df_subset=non_travel_sample,\n",
    "    max_pairs=4000,  \n",
    "    description=\"非旅遊類型簡訊\"\n",
    ")\n",
    "\n",
    "# ========== 合併結果 ==========\n",
    "all_similar_pairs = travel_pairs + non_travel_pairs\n",
    "\n",
    "print(f\"\\n📊 === 總結果 ===\")\n",
    "print(f\"旅遊類型相似對: {len(travel_pairs)} 個\")\n",
    "print(f\"非旅遊類型相似對: {len(non_travel_pairs)} 個\")\n",
    "print(f\"總相似對: {len(all_similar_pairs)} 個\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "606ec018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "旅遊類型相似對已保存到: sms_travel_similar_pairs.csv (400 對)\n",
      "非旅遊類型相似對已保存到: sms_non_travel_similar_pairs.csv (2000 對)\n",
      "完整結果已保存到: sms_all_similar_pairs_with_content.csv (2400 對)\n",
      "簡潔版結果已保存到: sms_all_similar_pairs.csv\n",
      "\n",
      "結果預覽:\n",
      "     簡訊id  相似簡訊id  類型\n",
      "0  254284   44913  旅遊\n",
      "1   73455   30973  旅遊\n",
      "2   73455  358354  旅遊\n",
      "3   30973  358354  旅遊\n",
      "4  134878   13188  旅遊\n",
      "5  296772   37977  旅遊\n",
      "6  296772  384483  旅遊\n",
      "7   37977  384483  旅遊\n",
      "8  303927  221770  旅遊\n",
      "9  248068  411326  旅遊\n"
     ]
    }
   ],
   "source": [
    "# 保存結果到 CSV（分類版本）\n",
    "def save_categorized_pairs_to_csv(travel_pairs: List[Tuple[int, int]], \n",
    "                                  non_travel_pairs: List[Tuple[int, int]], \n",
    "                                  df: pd.DataFrame):\n",
    "    \"\"\"保存分類的相似對到 CSV 檔案\"\"\"\n",
    "    \n",
    "    # 保存旅遊類型相似對\n",
    "    if travel_pairs:\n",
    "        travel_df = pd.DataFrame(travel_pairs, columns=[\"簡訊id\", \"相似簡訊id\"])\n",
    "        travel_df['類型'] = '旅遊'\n",
    "        travel_df.to_csv(\"sms_travel_similar_pairs.csv\", index=False, encoding='utf-8-sig')\n",
    "        print(f\"旅遊類型相似對已保存到: sms_travel_similar_pairs.csv ({len(travel_pairs)} 對)\")\n",
    "    \n",
    "    # 保存非旅遊類型相似對\n",
    "    if non_travel_pairs:\n",
    "        non_travel_df = pd.DataFrame(non_travel_pairs, columns=[\"簡訊id\", \"相似簡訊id\"])\n",
    "        non_travel_df['類型'] = '非旅遊'\n",
    "        non_travel_df.to_csv(\"sms_non_travel_similar_pairs.csv\", index=False, encoding='utf-8-sig')\n",
    "        print(f\"非旅遊類型相似對已保存到: sms_non_travel_similar_pairs.csv ({len(non_travel_pairs)} 對)\")\n",
    "    \n",
    "    # 保存合併結果\n",
    "    all_pairs = travel_pairs + non_travel_pairs\n",
    "    if all_pairs:\n",
    "        # 創建完整的結果 DataFrame\n",
    "        travel_df_full = pd.DataFrame(travel_pairs, columns=[\"簡訊id\", \"相似簡訊id\"])\n",
    "        travel_df_full['類型'] = '旅遊'\n",
    "        \n",
    "        non_travel_df_full = pd.DataFrame(non_travel_pairs, columns=[\"簡訊id\", \"相似簡訊id\"])\n",
    "        non_travel_df_full['類型'] = '非旅遊'\n",
    "        \n",
    "        combined_df = pd.concat([travel_df_full, non_travel_df_full], ignore_index=True)\n",
    "        \n",
    "        # 添加簡訊內容（可選）\n",
    "        def get_sms_content(sms_id):\n",
    "            content = df[df['sms_id'] == sms_id]['sms_body']\n",
    "            return content.iloc[0] if len(content) > 0 else \"未找到\"\n",
    "        \n",
    "        combined_df['簡訊內容'] = combined_df['簡訊id'].apply(get_sms_content)\n",
    "        combined_df['相似簡訊內容'] = combined_df['相似簡訊id'].apply(get_sms_content)\n",
    "        \n",
    "        # 保存完整結果\n",
    "        combined_df.to_csv(\"sms_all_similar_pairs_with_content.csv\", index=False, encoding='utf-8-sig')\n",
    "        print(f\"完整結果已保存到: sms_all_similar_pairs_with_content.csv ({len(all_pairs)} 對)\")\n",
    "        \n",
    "        # 保存簡潔版本（只有ID）\n",
    "        simple_df = combined_df[['簡訊id', '相似簡訊id', '類型']]\n",
    "        simple_df.to_csv(\"sms_all_similar_pairs.csv\", index=False, encoding='utf-8-sig')\n",
    "        print(f\"簡潔版結果已保存到: sms_all_similar_pairs.csv\")\n",
    "        \n",
    "        return combined_df\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 保存結果\n",
    "if travel_pairs or non_travel_pairs:\n",
    "    result_df = save_categorized_pairs_to_csv(travel_pairs, non_travel_pairs, df)\n",
    "    if result_df is not None:\n",
    "        print(\"\\n結果預覽:\")\n",
    "        print(result_df[['簡訊id', '相似簡訊id', '類型']].head(10))\n",
    "else:\n",
    "    print(\"未找到任何相似對\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142ad7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 分類相似對分析結果 ===\n",
      "旅遊類型相似對: 400 個\n",
      "非旅遊類型相似對: 2000 個\n",
      "總相似對: 2400 個\n",
      "\n",
      "🏖️ === 旅遊類型相似對樣本 ===\n",
      "\n",
      "--- 旅遊相似對 1 ---\n",
      "ID 37977: 您的出國旅遊計畫已經完成安排，所有的細節都已經確認！機票和住宿已經預訂成功，接送服務也已經安排好。請在出發前再次檢查您的護照有效期，並確認所有旅行資料。如果有任何問題或需求，隨時聯絡我們，我們將全程為您提供協助，祝您旅途愉快！\n",
      "ID 384483: 您的出國旅程已順利安排，感謝您選擇星際旅行社。我們已為您預訂好機票與住宿，請記得提前抵達機場辦理登機手續，並準備好護照及其他旅行文件。\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 旅遊相似對 2 ---\n",
      "ID 333656: 親愛的顧客，您的西班牙假期已經安排妥當。請確保在出發前準備好所有必要的文件，並提前到達機場辦理登機手續。如果您需要任何幫助，隨時聯絡我們的客服，祝您在西班牙度過一段美好的時光。\n",
      "ID 60433: 奇遇旅行社通知，您的澳大利亞悉尼與大堡礁之旅已經完成安排，您將於2024年7月25日出發，行程包括遊覽悉尼歌劇院、海港大橋，並前往大堡礁體驗浮潛。請攜帶舒適的鞋子和泳衣，為您準備一場難忘的海洋之旅。\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 旅遊相似對 3 ---\n",
      "ID 55667: 您的悉尼之旅已確認，出發時間為2024年8月5日，航班編號CX-102，請準時登機，祝您有個愉快的假期！\n",
      "ID 370056: 【旅天下】感謝您選擇我們的服務！您的機票與住宿已經確認。請注意出發前的準備事項，如有任何問題，請隨時聯絡我們的客服部門，我們會提供全方位協助。\n",
      "--------------------------------------------------\n",
      "\n",
      "🏢 === 非旅遊類型相似對樣本 ===\n",
      "\n",
      "--- 非旅遊相似對 1 ---\n",
      "ID 167818: 感謝您使用來福銀行的線上支付服務，您的付款已順利完成。若有其他付款或帳務問題，請不吝與我們的客服團隊聯繫，我們將竭誠為您服務。\n",
      "ID 409228: 您好，感謝您在星光購物網的訂購！您的包裹已順利出貨，預計於3個工作日內送達您指定的地址。請注意查收，若遇到配送問題，請即時聯絡我們的客服專線，我們將為您提供協助。若選擇超商取貨，請在三天內領取，過期將退回，謝謝您的合作。\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 非旅遊相似對 2 ---\n",
      "ID 27786: 鳳凰金業通知：感謝您使用本公司貸款服務，惟近期有期款遲延紀錄尚未處理，請盡速於本週內完成補繳。若仍有困難可申請寬限或重審方案，詳洽客服協助評估。\n",
      "ID 114315: 中泰融資關心您：您車貸帳號末四碼0912自5/25起已逾期，請於三日內繳清，避免產生滯納金與信用受損。若已繳款，請忽略本訊息。\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 非旅遊相似對 3 ---\n",
      "ID 85767: 尊敬的客戶，這是您在台灣銀行的催款通知。您的貸款款項尚未繳納，為了避免影響您的信用記錄，請儘速繳款。如果您已繳款，請忽略此訊息。如需協商還款計劃或有任何疑問，請隨時聯繫我們的客服部門。\n",
      "ID 363448: 您好，這是來自永豐銀行的付款提醒。您的貸款帳單金額尚未繳清，請儘速完成繳款。若有任何問題，請隨時聯絡我們的客服專線，我們將為您提供專業協助，謝謝！\n",
      "--------------------------------------------------\n",
      "\n",
      "📈 === 統計分析 ===\n",
      "旅遊簡訊覆蓋率: 51.1% (511/1000)\n",
      "非旅遊簡訊覆蓋率: 19.3% (3858/20000)\n"
     ]
    }
   ],
   "source": [
    "# 驗證和分析結果（分類版本）\n",
    "def analyze_categorized_pairs(travel_pairs: List[Tuple[int, int]], \n",
    "                             non_travel_pairs: List[Tuple[int, int]], \n",
    "                             df: pd.DataFrame):\n",
    "    \"\"\"分析分類相似對的質量\"\"\"\n",
    "    \n",
    "    print(f\"=== 分類相似對分析結果 ===\")\n",
    "    print(f\"旅遊類型相似對: {len(travel_pairs)} 個\")\n",
    "    print(f\"非旅遊類型相似對: {len(non_travel_pairs)} 個\")\n",
    "    print(f\"總相似對: {len(travel_pairs) + len(non_travel_pairs)} 個\")\n",
    "    \n",
    "    # 分析旅遊類型相似對\n",
    "    if travel_pairs:\n",
    "        print(f\"\\n🏖️ === 旅遊類型相似對樣本 ===\")\n",
    "        import random\n",
    "        sample_size = min(3, len(travel_pairs))\n",
    "        sample_pairs = random.sample(travel_pairs, sample_size)\n",
    "        \n",
    "        for i, (id1, id2) in enumerate(sample_pairs, 1):\n",
    "            sms1 = df[df['sms_id'] == id1]['sms_body'].iloc[0]\n",
    "            sms2 = df[df['sms_id'] == id2]['sms_body'].iloc[0]\n",
    "            \n",
    "            print(f\"\\n--- 旅遊相似對 {i} ---\")\n",
    "            print(f\"ID {id1}: {sms1}\")\n",
    "            print(f\"ID {id2}: {sms2}\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    # 分析非旅遊類型相似對\n",
    "    if non_travel_pairs:\n",
    "        print(f\"\\n🏢 === 非旅遊類型相似對樣本 ===\")\n",
    "        import random\n",
    "        sample_size = min(3, len(non_travel_pairs))\n",
    "        sample_pairs = random.sample(non_travel_pairs, sample_size)\n",
    "        \n",
    "        for i, (id1, id2) in enumerate(sample_pairs, 1):\n",
    "            sms1 = df[df['sms_id'] == id1]['sms_body'].iloc[0]\n",
    "            sms2 = df[df['sms_id'] == id2]['sms_body'].iloc[0]\n",
    "            \n",
    "            print(f\"\\n--- 非旅遊相似對 {i} ---\")\n",
    "            print(f\"ID {id1}: {sms1}\")\n",
    "            print(f\"ID {id2}: {sms2}\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    # 統計分析\n",
    "    if travel_pairs or non_travel_pairs:\n",
    "        print(f\"\\n📈 === 統計分析 ===\")\n",
    "        \n",
    "        # 旅遊類型覆蓋率\n",
    "        if travel_pairs:\n",
    "            travel_ids_in_pairs = set()\n",
    "            for id1, id2 in travel_pairs:\n",
    "                travel_ids_in_pairs.add(id1)\n",
    "                travel_ids_in_pairs.add(id2)\n",
    "            travel_coverage = len(travel_ids_in_pairs) / len(travel_sms) * 100\n",
    "            print(f\"旅遊簡訊覆蓋率: {travel_coverage:.1f}% ({len(travel_ids_in_pairs)}/{len(travel_sms)})\")\n",
    "        \n",
    "        # 非旅遊類型覆蓋率\n",
    "        if non_travel_pairs:\n",
    "            non_travel_ids_in_pairs = set()\n",
    "            for id1, id2 in non_travel_pairs:\n",
    "                non_travel_ids_in_pairs.add(id1)\n",
    "                non_travel_ids_in_pairs.add(id2)\n",
    "            non_travel_coverage = len(non_travel_ids_in_pairs) / len(non_travel_sample) * 100\n",
    "            print(f\"非旅遊簡訊覆蓋率: {non_travel_coverage:.1f}% ({len(non_travel_ids_in_pairs)}/{len(non_travel_sample)})\")\n",
    "\n",
    "# 分析結果\n",
    "if travel_pairs or non_travel_pairs:\n",
    "    analyze_categorized_pairs(travel_pairs, non_travel_pairs, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e55acf1",
   "metadata": {},
   "source": [
    "## negative gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67299ab",
   "metadata": {},
   "source": [
    "## 負樣本生成\n",
    "\n",
    "使用 LLM 批量評估（5選2）方式生成高質量負樣本。\n",
    "\n",
    "### 🔧 參數控制\n",
    "\n",
    "- **負樣本數量**：可以在下面的 cell 中調整 `NEGATIVE_PAIRS_COUNT` 變數\n",
    "- **批量策略**：每5個候選對選出最不匹配的2個\n",
    "- **配對策略**：60% 跨類型 + 40% 同類型隨機配對\n",
    "- **質量保證**：LLM 評估確保負樣本真正不匹配\n",
    "\n",
    "### 💡 建議數量\n",
    "\n",
    "- **小規模測試**：50-100 個負樣本\n",
    "- **中等規模**：500-1000 個負樣本  \n",
    "- **大規模訓練**：1000+ 個負樣本\n",
    "\n",
    "根據您的正樣本數量，建議負樣本數量為正樣本的 0.5-2 倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c4e04b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 負樣本數量配置選項 ===\n",
      "預設配置選項:\n",
      "  測試: 50 個負樣本\n",
      "  小規模: 200 個負樣本\n",
      "  中規模: 500 個負樣本\n",
      "  大規模: 1000 個負樣本\n",
      "  超大規模: 2000 個負樣本\n",
      "\n",
      "✅ 使用自定義配置: 1200 個負樣本\n",
      "\n",
      "💡 提示: 請先執行正樣本生成以獲得更準確的建議\n",
      "\n",
      "🚀 準備生成 1200 個負樣本...\n"
     ]
    }
   ],
   "source": [
    "# 負樣本數量配置 - 快速選擇\n",
    "print(\"=== 負樣本數量配置選項 ===\")\n",
    "\n",
    "# 🔧 選擇一個預設配置，或自定義數量\n",
    "config_options = {\n",
    "    \"測試\": 50,\n",
    "    \"小規模\": 200, \n",
    "    \"中規模\": 500,\n",
    "    \"大規模\": 1000,\n",
    "    \"超大規模\": 2000\n",
    "}\n",
    "\n",
    "print(\"預設配置選項:\")\n",
    "for name, count in config_options.items():\n",
    "    print(f\"  {name}: {count} 個負樣本\")\n",
    "\n",
    "# 🎯 在這裡選擇您想要的配置\n",
    "#SELECTED_CONFIG = \"中規模\"  # 📝 修改這裡選擇不同配置\n",
    "# 或者直接設定自定義數量\n",
    "CUSTOM_NEGATIVE_COUNT = 1200  # 📝 取消註釋並設定自定義數量\n",
    "\n",
    "# 應用配置\n",
    "if 'CUSTOM_NEGATIVE_COUNT' in locals():\n",
    "    NEGATIVE_PAIRS_COUNT = CUSTOM_NEGATIVE_COUNT\n",
    "    print(f\"\\n✅ 使用自定義配置: {NEGATIVE_PAIRS_COUNT} 個負樣本\")\n",
    "elif SELECTED_CONFIG in config_options:\n",
    "    NEGATIVE_PAIRS_COUNT = config_options[SELECTED_CONFIG]\n",
    "    print(f\"\\n✅ 使用 '{SELECTED_CONFIG}' 配置: {NEGATIVE_PAIRS_COUNT} 個負樣本\")\n",
    "else:\n",
    "    NEGATIVE_PAIRS_COUNT = 500  # 預設值\n",
    "    print(f\"\\n⚠️  配置無效，使用預設值: {NEGATIVE_PAIRS_COUNT} 個負樣本\")\n",
    "\n",
    "# 根據現有正樣本數量給出建議\n",
    "if 'travel_pairs' in locals() and 'non_travel_pairs' in locals():\n",
    "    total_positive = len(travel_pairs) + len(non_travel_pairs)\n",
    "    ratio = NEGATIVE_PAIRS_COUNT / total_positive if total_positive > 0 else 0\n",
    "    \n",
    "    print(f\"\\n📊 === 樣本平衡分析 ===\")\n",
    "    print(f\"正樣本總數: {total_positive}\")\n",
    "    print(f\"預計負樣本: {NEGATIVE_PAIRS_COUNT}\")\n",
    "    print(f\"負正比例: {ratio:.2f} (負樣本/正樣本)\")\n",
    "    \n",
    "    if ratio < 0.5:\n",
    "        print(\"💡 建議: 負樣本較少，可能需要增加以平衡數據集\")\n",
    "    elif ratio > 2.0:\n",
    "        print(\"💡 建議: 負樣本較多，可能影響訓練效率\")\n",
    "    else:\n",
    "        print(\"✅ 負正樣本比例合理\")\n",
    "else:\n",
    "    print(\"\\n💡 提示: 請先執行正樣本生成以獲得更準確的建議\")\n",
    "\n",
    "print(f\"\\n🚀 準備生成 {NEGATIVE_PAIRS_COUNT} 個負樣本...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f630544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始生成高質量負樣本...\n",
      "🎯 目標生成: 1200 個負樣本對\n",
      "📅 預估處理時間: 40.0 分鐘 (600 批次, 600 API調用)\n",
      "=== 負樣本生成策略 ===\n",
      "旅遊類型簡訊: 1000 筆\n",
      "非旅遊類型簡訊: 208481 筆\n",
      "目標生成負樣本對: 1200 個\n",
      "\n",
      "開始生成負樣本，預計需要 600 批次處理\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "負樣本生成進度:  99%|█████████▉| 1192/1200 [1:04:45<00:26,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "負樣本生成完成！總共生成 1192 個負樣本對\n",
      "\n",
      "📊 === 負樣本生成結果 ===\n",
      "✅ 成功生成: 1192 個負樣本對\n",
      "🎯 目標數量: 1200\n",
      "📈 完成率: 99.3%\n",
      "⚠️  短缺 8 個負樣本，可能是由於API限制或數據限制\n",
      "💡 建議: 可以重新執行此cell或調整批次大小\n",
      "\n",
      "=== 負樣本質量分析 ===\n",
      "跨類型負樣本: 1183 個 (99.2%)\n",
      "同類型負樣本: 9 個 (0.8%)\n",
      "\n",
      "=== 負樣本例子 ===\n",
      "\n",
      "--- 負樣本 1 ---\n",
      "ID 418547 (label=nan): 您的越南胡志明市與美奈海灘之旅已確定！由世界旅遊公司安排的這次行程將帶您遊覽胡志明市的歷史景點，並在美奈的沙灘上放鬆。行程中還安排了越南的特色美食與當地文化體驗，讓您充分感受越南的熱情。\n",
      "ID 248141 (label=nan): 您好，這是來自中信銀行的提醒。您的信用卡款項至今尚未繳納，並已經過了繳款期限。為了避免影響您的信用記錄及產生滯納金，請儘速繳納所欠款項。如果已經繳納，請忽略此簡訊。若有任何問題，歡迎隨時來電詢問。\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 負樣本 2 ---\n",
      "ID 359686 (label=1.0): 【巴黎自由行】限時優惠，讓你在浪漫之都輕鬆享受無憂旅遊！行程安排精緻，現正開放報名中，快來參加！https://paristravel.com\n",
      "ID 128624 (label=nan): 您好，您於中信銀行申請之卡友貸款至今尚欠NT$15,700，逾期已產生違約利息，若今日未清償將由第三方催收公司處理，請儘速處理。\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 負樣本 3 ---\n",
      "ID 243587 (label=1.0): 莊哲銘推薦使用「旅圈筆記APP」製作個人旅遊規劃表，可共享行程給同行者，功能包含換匯提醒、天氣預報、票券提醒！\n",
      "ID 12142 (label=nan): 台大醫院健康管理中心特別推出秋冬季護肝健檢專案，內容包含肝功能抽血、腹部超音波與專業醫師解說報告，預約即贈肝臟保健小手冊。\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "RPM = 60                # requests/min\n",
    "WINDOW = 60             # sec\n",
    "MAX_RETRY = 3           # retries\n",
    "MODEL_ID = \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"\n",
    "\n",
    "# 請求紀錄\n",
    "_req_log = []\n",
    "\n",
    "def _throttle():\n",
    "    \"\"\"簡單的限流機制\"\"\"\n",
    "    now = time.time()\n",
    "    # 清理超過時間窗口的記錄\n",
    "    _req_log[:] = [t for t in _req_log if now - t < WINDOW]\n",
    "    \n",
    "    # 檢查是否需要等待\n",
    "    if len(_req_log) >= RPM:\n",
    "        wait_time = WINDOW - (now - _req_log[0])\n",
    "        if wait_time > 0:\n",
    "            time.sleep(wait_time)\n",
    "    \n",
    "    _req_log.append(now)\n",
    "\n",
    "# 負樣本生成 - 找出最不匹配的簡訊對\n",
    "def generate_negative_pairs_batch(df: pd.DataFrame, max_negative_pairs: int = 1000) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    生成負樣本：找出最不匹配的簡訊對\n",
    "    使用批量比較，一次給模型 5 個選擇進行評估\n",
    "    \n",
    "    策略：\n",
    "    1. 跨類型配對（旅遊 vs 非旅遊）\n",
    "    2. 同類型但主題差異大的配對\n",
    "    3. 批量評估 5 個候選對，選出最不匹配的\n",
    "    \n",
    "    Args:\n",
    "        df: 完整的簡訊 DataFrame\n",
    "        max_negative_pairs: 最大負樣本對數量\n",
    "        \n",
    "    Returns:\n",
    "        負樣本對的列表 [(id1, id2), ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    negative_pairs = []\n",
    "    \n",
    "    # 分離不同類型的簡訊\n",
    "    travel_df = df[df['label'] == 1].copy()\n",
    "    non_travel_df = df[df['label'] != 1].copy()\n",
    "    \n",
    "    print(f\"=== 負樣本生成策略 ===\")\n",
    "    print(f\"旅遊類型簡訊: {len(travel_df)} 筆\")\n",
    "    print(f\"非旅遊類型簡訊: {len(non_travel_df)} 筆\")\n",
    "    print(f\"目標生成負樣本對: {max_negative_pairs} 個\")\n",
    "    \n",
    "    # 負樣本評估 prompt\n",
    "    negative_evaluation_prompt = textwrap.dedent(\n",
    "        \"\"\"\n",
    "        你是一個專業的文本相似性判斷助手。現在有 5 組簡訊對，請評估每組的相似性，並選出其中最不相似的 2 組。\n",
    "\n",
    "        評估標準：\n",
    "        1. 主題差異：主題越不同，負樣本質量越好\n",
    "        2. 意圖差異：目的越不同，負樣本質量越好  \n",
    "        3. 內容差異：內容越無關，負樣本質量越好\n",
    "        4. 語境差異：使用場景越不同，負樣本質量越好\n",
    "\n",
    "        請仔細比較以下 5 組簡訊對：\n",
    "\n",
    "        組A:\n",
    "        簡訊1: {sms_a1}\n",
    "        簡訊2: {sms_a2}\n",
    "\n",
    "        組B:\n",
    "        簡訊1: {sms_b1}\n",
    "        簡訊2: {sms_b2}\n",
    "\n",
    "        組C:\n",
    "        簡訊1: {sms_c1}\n",
    "        簡訊2: {sms_c2}\n",
    "\n",
    "        組D:\n",
    "        簡訊1: {sms_d1}\n",
    "        簡訊2: {sms_d2}\n",
    "\n",
    "        組E:\n",
    "        簡訊1: {sms_e1}\n",
    "        簡訊2: {sms_e2}\n",
    "\n",
    "        請按照以下格式回答，選出最不相似的 2 組：\n",
    "        最不相似組1: [組別字母]\n",
    "        最不相似組2: [組別字母]\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    def evaluate_negative_batch(candidate_pairs: List[Tuple[Tuple[int, str], Tuple[int, str]]]) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        評估一批候選負樣本對，返回最不匹配的 2 個\n",
    "        \n",
    "        Args:\n",
    "            candidate_pairs: [((id1, content1), (id2, content2)), ...] 最多 5 個候選對\n",
    "            \n",
    "        Returns:\n",
    "            最不匹配的 2 個對 [(id1, id2), ...]\n",
    "        \"\"\"\n",
    "        if len(candidate_pairs) != 5:\n",
    "            return []\n",
    "        \n",
    "        # 準備 prompt 參數\n",
    "        prompt_params = {}\n",
    "        for i, ((id1, content1), (id2, content2)) in enumerate(candidate_pairs):\n",
    "            group_letter = chr(ord('a') + i)  # a, b, c, d, e\n",
    "            prompt_params[f'sms_{group_letter}1'] = content1\n",
    "            prompt_params[f'sms_{group_letter}2'] = content2\n",
    "        \n",
    "        prompt = negative_evaluation_prompt.format(**prompt_params)\n",
    "        \n",
    "        client = get_current_together_client()\n",
    "        \n",
    "        for attempt in range(MAX_RETRY):\n",
    "            try:\n",
    "                _throttle()\n",
    "                response = client.chat.completions.create(\n",
    "                    model=MODEL_ID,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    max_tokens=50,\n",
    "                    temperature=0.0,\n",
    "                    stream=False,\n",
    "                )\n",
    "                \n",
    "                result = response.choices[0].message.content.strip()\n",
    "                \n",
    "                # 強化版解析邏輯\n",
    "                selected_pairs = []\n",
    "                lines = result.split('\\n')\n",
    "                \n",
    "                for line in lines:\n",
    "                    if '最不相似組' in line and ':' in line:\n",
    "                        try:\n",
    "                            # 提取冒號後的內容\n",
    "                            content_after_colon = line.split(':')[1].strip()\n",
    "                            \n",
    "                            # 查找組別字母 - 支持多種格式\n",
    "                            group_letter = None\n",
    "                            \n",
    "                            # 方法1: 查找 \"組X\" 格式\n",
    "                            import re\n",
    "                            group_match = re.search(r'組([A-Ea-e])', content_after_colon)\n",
    "                            if group_match:\n",
    "                                group_letter = group_match.group(1).lower()\n",
    "                            \n",
    "                            # 方法2: 查找單獨的字母\n",
    "                            if not group_letter:\n",
    "                                letter_match = re.search(r'\\b([A-Ea-e])\\b', content_after_colon)\n",
    "                                if letter_match:\n",
    "                                    group_letter = letter_match.group(1).lower()\n",
    "                            \n",
    "                            # 方法3: 直接查找 a-e 字母\n",
    "                            if not group_letter:\n",
    "                                for letter in ['a', 'b', 'c', 'd', 'e']:\n",
    "                                    if letter in content_after_colon.lower():\n",
    "                                        group_letter = letter\n",
    "                                        break\n",
    "                            \n",
    "                            if group_letter and group_letter in ['a', 'b', 'c', 'd', 'e']:\n",
    "                                group_index = ord(group_letter) - ord('a')\n",
    "                                if group_index < len(candidate_pairs):\n",
    "                                    pair = candidate_pairs[group_index]\n",
    "                                    selected_pair = (pair[0][0], pair[1][0])  # (id1, id2)\n",
    "                                    selected_pairs.append(selected_pair)\n",
    "    \n",
    "                            else:\n",
    "                                print(f\"無法識別組別: '{content_after_colon}'\")\n",
    "                                \n",
    "                        except Exception as parse_error:\n",
    "                            print(f\"解析錯誤: {parse_error}\")\n",
    "                            continue\n",
    "            \n",
    "                \n",
    "                # 確保最多返回 2 個對，並去重\n",
    "                unique_pairs = []\n",
    "                for pair in selected_pairs:\n",
    "                    if pair not in unique_pairs:\n",
    "                        unique_pairs.append(pair)\n",
    "                \n",
    "                return unique_pairs[:2]\n",
    "                \n",
    "            except Exception as e:\n",
    "                if attempt + 1 >= MAX_RETRY:\n",
    "                    print(f\"負樣本評估失敗: {e}\")\n",
    "                    return []\n",
    "                \n",
    "                print(f\"嘗試 {attempt + 1} 失敗: {e}. 60秒後重試...\")\n",
    "                time.sleep(60)\n",
    "        \n",
    "        return []\n",
    "    \n",
    "    # 生成候選負樣本對\n",
    "    def generate_candidate_pairs(travel_df: pd.DataFrame, non_travel_df: pd.DataFrame, num_candidates: int) -> List[Tuple[Tuple[int, str], Tuple[int, str]]]:\n",
    "        \"\"\"生成候選負樣本對\"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        # 策略1: 跨類型配對 (60%)\n",
    "        cross_type_count = int(num_candidates * 0.6)\n",
    "        for _ in range(cross_type_count):\n",
    "            if len(travel_df) > 0 and len(non_travel_df) > 0:\n",
    "                travel_sample = travel_df.sample(n=1).iloc[0]\n",
    "                non_travel_sample = non_travel_df.sample(n=1).iloc[0]\n",
    "                \n",
    "                candidates.append((\n",
    "                    (travel_sample['sms_id'], travel_sample['sms_body']),\n",
    "                    (non_travel_sample['sms_id'], non_travel_sample['sms_body'])\n",
    "                ))\n",
    "        \n",
    "        # 策略2: 同類型隨機配對 (40%)\n",
    "        remaining_count = num_candidates - len(candidates)\n",
    "        \n",
    "        # 旅遊類型內隨機配對\n",
    "        travel_internal_count = remaining_count // 2\n",
    "        if len(travel_df) >= 2:\n",
    "            for _ in range(travel_internal_count):\n",
    "                samples = travel_df.sample(n=2)\n",
    "                sample1, sample2 = samples.iloc[0], samples.iloc[1]\n",
    "                \n",
    "                candidates.append((\n",
    "                    (sample1['sms_id'], sample1['sms_body']),\n",
    "                    (sample2['sms_id'], sample2['sms_body'])\n",
    "                ))\n",
    "        \n",
    "        # 非旅遊類型內隨機配對\n",
    "        non_travel_internal_count = num_candidates - len(candidates)\n",
    "        if len(non_travel_df) >= 2:\n",
    "            for _ in range(non_travel_internal_count):\n",
    "                samples = non_travel_df.sample(n=2)\n",
    "                sample1, sample2 = samples.iloc[0], samples.iloc[1]\n",
    "                \n",
    "                candidates.append((\n",
    "                    (sample1['sms_id'], sample1['sms_body']),\n",
    "                    (sample2['sms_id'], sample2['sms_body'])\n",
    "                ))\n",
    "        \n",
    "        return candidates\n",
    "    \n",
    "    # 主要處理邏輯\n",
    "    total_batches = (max_negative_pairs + 1) // 2  # 每批最多生成 2 個負樣本\n",
    "    \n",
    "    print(f\"\\n開始生成負樣本，預計需要 {total_batches} 批次處理\")\n",
    "    \n",
    "    with tqdm(total=max_negative_pairs, desc=\"負樣本生成進度\") as pbar:\n",
    "        for batch_idx in range(total_batches):\n",
    "            if len(negative_pairs) >= max_negative_pairs:\n",
    "                break\n",
    "            \n",
    "            # 生成 5 個候選對\n",
    "            candidates = generate_candidate_pairs(travel_df, non_travel_df, 5)\n",
    "            if len(candidates) == 5:\n",
    "                # 評估並選出最不匹配的 2 個\n",
    "                selected_negative_pairs = evaluate_negative_batch(candidates)\n",
    "                for pair in selected_negative_pairs:\n",
    "                    if len(negative_pairs) < max_negative_pairs:\n",
    "                        negative_pairs.append(pair)\n",
    "                        pbar.update(1)\n",
    "                        \n",
    "                        # 顯示找到的負樣本\n",
    "                        id1, id2 = pair\n",
    "                        sms1 = df[df['sms_id'] == id1]['sms_body'].iloc[0]\n",
    "                        sms2 = df[df['sms_id'] == id2]['sms_body'].iloc[0]\n",
    "                        \n",
    "            else:\n",
    "                print(f\"警告: 批次 {batch_idx + 1} 候選對不足 5 個\")\n",
    "    \n",
    "    print(f\"\\n負樣本生成完成！總共生成 {len(negative_pairs)} 個負樣本對\")\n",
    "    return negative_pairs\n",
    "\n",
    "# 執行負樣本生成 - 使用配置的數量\n",
    "print(\"開始生成高質量負樣本...\")\n",
    "\n",
    "# 檢查是否有預設的數量配置\n",
    "if 'NEGATIVE_PAIRS_COUNT' not in locals():\n",
    "    NEGATIVE_PAIRS_COUNT = 500  # 預設值\n",
    "    print(f\"⚠️  未找到配置，使用預設值: {NEGATIVE_PAIRS_COUNT} 個負樣本\")\n",
    "\n",
    "print(f\"🎯 目標生成: {NEGATIVE_PAIRS_COUNT} 個負樣本對\")\n",
    "\n",
    "# 估算所需時間\n",
    "estimated_batches = (NEGATIVE_PAIRS_COUNT + 1) // 2\n",
    "estimated_api_calls = estimated_batches\n",
    "estimated_minutes = estimated_api_calls / (RPM / 4)  # 考慮4個API key的並行\n",
    "print(f\"📅 預估處理時間: {estimated_minutes:.1f} 分鐘 ({estimated_batches} 批次, {estimated_api_calls} API調用)\")\n",
    "\n",
    "# 執行生成\n",
    "negative_pairs = generate_negative_pairs_batch(df, max_negative_pairs=NEGATIVE_PAIRS_COUNT)\n",
    "\n",
    "print(f\"\\n📊 === 負樣本生成結果 ===\")\n",
    "print(f\"✅ 成功生成: {len(negative_pairs)} 個負樣本對\")\n",
    "print(f\"🎯 目標數量: {NEGATIVE_PAIRS_COUNT}\")\n",
    "print(f\"📈 完成率: {len(negative_pairs)/NEGATIVE_PAIRS_COUNT*100:.1f}%\")\n",
    "\n",
    "if len(negative_pairs) < NEGATIVE_PAIRS_COUNT:\n",
    "    shortfall = NEGATIVE_PAIRS_COUNT - len(negative_pairs)\n",
    "    print(f\"⚠️  短缺 {shortfall} 個負樣本，可能是由於API限制或數據限制\")\n",
    "    print(\"💡 建議: 可以重新執行此cell或調整批次大小\")\n",
    "\n",
    "# 分析負樣本質量\n",
    "def analyze_negative_pairs(negative_pairs: List[Tuple[int, int]], df: pd.DataFrame):\n",
    "    \"\"\"分析負樣本的質量\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== 負樣本質量分析 ===\")\n",
    "    \n",
    "    cross_type_count = 0\n",
    "    same_type_count = 0\n",
    "    \n",
    "    for id1, id2 in negative_pairs:\n",
    "        label1 = df[df['sms_id'] == id1]['label'].iloc[0]\n",
    "        label2 = df[df['sms_id'] == id2]['label'].iloc[0]\n",
    "        \n",
    "        if label1 != label2:\n",
    "            cross_type_count += 1\n",
    "        else:\n",
    "            same_type_count += 1\n",
    "    \n",
    "    print(f\"跨類型負樣本: {cross_type_count} 個 ({cross_type_count/len(negative_pairs)*100:.1f}%)\")\n",
    "    print(f\"同類型負樣本: {same_type_count} 個 ({same_type_count/len(negative_pairs)*100:.1f}%)\")\n",
    "    \n",
    "    # 顯示一些負樣本例子\n",
    "    print(f\"\\n=== 負樣本例子 ===\")\n",
    "    import random\n",
    "    sample_size = min(3, len(negative_pairs))\n",
    "    sample_pairs = random.sample(negative_pairs, sample_size)\n",
    "    \n",
    "    for i, (id1, id2) in enumerate(sample_pairs, 1):\n",
    "        sms1 = df[df['sms_id'] == id1]['sms_body'].iloc[0]\n",
    "        sms2 = df[df['sms_id'] == id2]['sms_body'].iloc[0]\n",
    "        label1 = df[df['sms_id'] == id1]['label'].iloc[0]\n",
    "        label2 = df[df['sms_id'] == id2]['label'].iloc[0]\n",
    "        \n",
    "        print(f\"\\n--- 負樣本 {i} ---\")\n",
    "        print(f\"ID {id1} (label={label1}): {sms1}\")\n",
    "        print(f\"ID {id2} (label={label2}): {sms2}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "if negative_pairs:\n",
    "    analyze_negative_pairs(negative_pairs, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42332ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完整負樣本結果已保存到: sms_negative_pairs_with_content.csv (1192 對)\n",
      "簡潔負樣本結果已保存到: sms_negative_pairs.csv\n",
      "\n",
      "=== 負樣本結果預覽 ===\n",
      "     簡訊id  相似簡訊id 配對類型\n",
      "0   19635  267771  跨類型\n",
      "1  329175   15069  跨類型\n",
      "2  291076  393114  跨類型\n",
      "3  255383   75606  跨類型\n",
      "4   41187  391525  跨類型\n",
      "5  282119  220849  跨類型\n",
      "6  137836  134915  跨類型\n",
      "7  185111  259560  跨類型\n",
      "8  272034  342824  跨類型\n",
      "9  319287  402629  跨類型\n",
      "\n",
      "✅ 負樣本生成和保存完成！\n",
      "📁 已保存檔案:\n",
      "  - sms_negative_pairs.csv (簡潔版)\n",
      "  - sms_negative_pairs_with_content.csv (完整版)\n"
     ]
    }
   ],
   "source": [
    "# 保存負樣本結果\n",
    "def save_negative_pairs_to_csv(negative_pairs: List[Tuple[int, int]], df: pd.DataFrame):\n",
    "    \"\"\"保存負樣本對到 CSV 檔案\"\"\"\n",
    "    \n",
    "    if not negative_pairs:\n",
    "        print(\"沒有負樣本可保存\")\n",
    "        return None\n",
    "    \n",
    "    # 創建負樣本 DataFrame\n",
    "    negative_df = pd.DataFrame(negative_pairs, columns=[\"簡訊id\", \"相似簡訊id\"])\n",
    "    negative_df['類型'] = '負樣本'\n",
    "    \n",
    "    # 添加簡訊內容和標籤\n",
    "    def get_sms_info(sms_id):\n",
    "        row = df[df['sms_id'] == sms_id]\n",
    "        if len(row) > 0:\n",
    "            return row.iloc[0]['sms_body'], row.iloc[0]['label']\n",
    "        return \"未找到\", -1\n",
    "    \n",
    "    # 獲取簡訊內容和標籤\n",
    "    sms1_info = negative_df['簡訊id'].apply(get_sms_info)\n",
    "    sms2_info = negative_df['相似簡訊id'].apply(get_sms_info)\n",
    "    \n",
    "    negative_df['簡訊內容'] = [info[0] for info in sms1_info]\n",
    "    negative_df['簡訊標籤'] = [info[1] for info in sms1_info]\n",
    "    negative_df['相似簡訊內容'] = [info[0] for info in sms2_info]\n",
    "    negative_df['相似簡訊標籤'] = [info[1] for info in sms2_info]\n",
    "    \n",
    "    # 添加配對類型分析\n",
    "    def get_pair_type(label1, label2):\n",
    "        if label1 == label2:\n",
    "            return '同類型'\n",
    "        else:\n",
    "            return '跨類型'\n",
    "    \n",
    "    negative_df['配對類型'] = negative_df.apply(\n",
    "        lambda row: get_pair_type(row['簡訊標籤'], row['相似簡訊標籤']), axis=1\n",
    "    )\n",
    "    \n",
    "    # 保存完整版本\n",
    "    negative_df.to_csv(\"sms_negative_pairs_with_content.csv\", index=False, encoding='utf-8-sig')\n",
    "    print(f\"完整負樣本結果已保存到: sms_negative_pairs_with_content.csv ({len(negative_pairs)} 對)\")\n",
    "    \n",
    "    # 保存簡潔版本（只有ID和類型）\n",
    "    simple_negative_df = negative_df[['簡訊id', '相似簡訊id', '類型', '配對類型']]\n",
    "    simple_negative_df.to_csv(\"sms_negative_pairs.csv\", index=False, encoding='utf-8-sig')\n",
    "    print(f\"簡潔負樣本結果已保存到: sms_negative_pairs.csv\")\n",
    "    \n",
    "    return negative_df\n",
    "\n",
    "# 合併正負樣本結果\n",
    "def create_complete_training_dataset(travel_pairs: List[Tuple[int, int]], \n",
    "                                   non_travel_pairs: List[Tuple[int, int]],\n",
    "                                   negative_pairs: List[Tuple[int, int]], \n",
    "                                   df: pd.DataFrame):\n",
    "    \"\"\"創建完整的訓練數據集（正樣本 + 負樣本）\"\"\"\n",
    "    \n",
    "    all_pairs = []\n",
    "    \n",
    "    # 添加旅遊正樣本\n",
    "    for pair in travel_pairs:\n",
    "        all_pairs.append({\n",
    "            '簡訊id': pair[0],\n",
    "            '相似簡訊id': pair[1],\n",
    "            '標籤': 1,  # 正樣本\n",
    "            '樣本類型': '旅遊正樣本'\n",
    "        })\n",
    "    \n",
    "    # 添加非旅遊正樣本\n",
    "    for pair in non_travel_pairs:\n",
    "        all_pairs.append({\n",
    "            '簡訊id': pair[0],\n",
    "            '相似簡訊id': pair[1],\n",
    "            '標籤': 1,  # 正樣本\n",
    "            '樣本類型': '非旅遊正樣本'\n",
    "        })\n",
    "    \n",
    "    # 添加負樣本\n",
    "    for pair in negative_pairs:\n",
    "        all_pairs.append({\n",
    "            '簡訊id': pair[0],\n",
    "            '相似簡訊id': pair[1],\n",
    "            '標籤': 0,  # 負樣本\n",
    "            '樣本類型': '負樣本'\n",
    "        })\n",
    "    \n",
    "    # 創建完整數據集\n",
    "    complete_df = pd.DataFrame(all_pairs)\n",
    "    \n",
    "    # 添加簡訊內容\n",
    "    def get_sms_content(sms_id):\n",
    "        content = df[df['sms_id'] == sms_id]['sms_body']\n",
    "        return content.iloc[0] if len(content) > 0 else \"未找到\"\n",
    "    \n",
    "    complete_df['簡訊內容'] = complete_df['簡訊id'].apply(get_sms_content)\n",
    "    complete_df['相似簡訊內容'] = complete_df['相似簡訊id'].apply(get_sms_content)\n",
    "    \n",
    "    # 保存完整訓練數據集\n",
    "    complete_df.to_csv(\"sms_complete_training_dataset.csv\", index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 統計信息\n",
    "    print(f\"\\n📊 === 完整訓練數據集統計 ===\")\n",
    "    print(f\"旅遊正樣本: {len(travel_pairs)} 對\")\n",
    "    print(f\"非旅遊正樣本: {len(non_travel_pairs)} 對\")\n",
    "    print(f\"負樣本: {len(negative_pairs)} 對\")\n",
    "    print(f\"總樣本: {len(all_pairs)} 對\")\n",
    "    \n",
    "    positive_ratio = (len(travel_pairs) + len(non_travel_pairs)) / len(all_pairs) * 100\n",
    "    negative_ratio = len(negative_pairs) / len(all_pairs) * 100\n",
    "    \n",
    "    print(f\"正樣本比例: {positive_ratio:.1f}%\")\n",
    "    print(f\"負樣本比例: {negative_ratio:.1f}%\")\n",
    "    print(f\"完整訓練數據集已保存到: sms_complete_training_dataset.csv\")\n",
    "    \n",
    "    return complete_df\n",
    "\n",
    "# 保存負樣本結果\n",
    "if negative_pairs:\n",
    "    negative_result_df = save_negative_pairs_to_csv(negative_pairs, df)\n",
    "    \n",
    "    # 顯示負樣本結果預覽\n",
    "    if negative_result_df is not None:\n",
    "        print(f\"\\n=== 負樣本結果預覽 ===\")\n",
    "        print(negative_result_df[['簡訊id', '相似簡訊id', '配對類型']].head(10))\n",
    "        \n",
    "        print(\"\\n✅ 負樣本生成和保存完成！\")\n",
    "        print(\"📁 已保存檔案:\")\n",
    "        print(\"  - sms_negative_pairs.csv (簡潔版)\")\n",
    "        print(\"  - sms_negative_pairs_with_content.csv (完整版)\")\n",
    "else:\n",
    "    print(\"沒有生成負樣本，請先執行負樣本生成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ea4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sms_cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
